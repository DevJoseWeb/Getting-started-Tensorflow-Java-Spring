{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_data_w_target = [];\n",
    "# prepare data\n",
    "# the data comes originally with all the examples ordered, so to get a meaningful test sample, we need to shuffle it\n",
    "# add the target to the data to be able to shuffle and partion later\n",
    "for i in range(len(iris.data)):\n",
    "    value = numpy.append(iris.data[i], iris.target[i])\n",
    "    iris_data_w_target.append(value)\n",
    "\n",
    "#print(iris_data_w_target)\n",
    "feature_names = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(data = iris_data_w_target, columns = feature_names )\n",
    "\n",
    "# shuffle our data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# partition of our data\n",
    "# we reserve the 20% of the total records for testing\n",
    "test_len = (len(df) * 20)//100;\n",
    "training_df = df[test_len:]\n",
    "test_df = df[:test_len]\n",
    "\n",
    "\n",
    "#print(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\_domine3\\AppData\\Local\\Temp\\tmp388xdcy3\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_train_distribute': None, '_keep_checkpoint_max': 5, '_save_checkpoints_steps': None, '_model_dir': 'C:\\\\Users\\\\_domine3\\\\AppData\\\\Local\\\\Temp\\\\tmp388xdcy3', '_tf_random_seed': None, '_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000001489DF60>, '_task_id': 0, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_master': '', '_session_config': None, '_num_worker_replicas': 1, '_is_chief': True, '_num_ps_replicas': 0, '_task_type': 'worker', '_evaluation_master': '', '_save_checkpoints_secs': 600}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\_domine3\\AppData\\Local\\Temp\\tmp388xdcy3\\model.ckpt.\n",
      "INFO:tensorflow:loss = 139.2976, step = 1\n",
      "INFO:tensorflow:global_step/sec: 386.1\n",
      "INFO:tensorflow:loss = 15.095531, step = 101 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.821\n",
      "INFO:tensorflow:loss = 8.675394, step = 201 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.46\n",
      "INFO:tensorflow:loss = 9.85504, step = 301 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.643\n",
      "INFO:tensorflow:loss = 6.7131195, step = 401 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.81\n",
      "INFO:tensorflow:loss = 4.9423385, step = 501 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.319\n",
      "INFO:tensorflow:loss = 5.3761263, step = 601 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.797\n",
      "INFO:tensorflow:loss = 3.7728348, step = 701 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.715\n",
      "INFO:tensorflow:loss = 3.9594324, step = 801 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.423\n",
      "INFO:tensorflow:loss = 3.5536861, step = 901 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.432\n",
      "INFO:tensorflow:loss = 4.591949, step = 1001 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.759\n",
      "INFO:tensorflow:loss = 4.2310295, step = 1101 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.729\n",
      "INFO:tensorflow:loss = 2.5031085, step = 1201 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.667\n",
      "INFO:tensorflow:loss = 1.7853639, step = 1301 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.642\n",
      "INFO:tensorflow:loss = 1.6998769, step = 1401 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.46\n",
      "INFO:tensorflow:loss = 3.4077053, step = 1501 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.625\n",
      "INFO:tensorflow:loss = 6.1948853, step = 1601 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.486\n",
      "INFO:tensorflow:loss = 2.1856198, step = 1701 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.634\n",
      "INFO:tensorflow:loss = 2.9113278, step = 1801 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.934\n",
      "INFO:tensorflow:loss = 2.9161034, step = 1901 (0.214 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\_domine3\\AppData\\Local\\Temp\\tmp388xdcy3\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.8931274.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x129ed320>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the classifier\n",
    "\n",
    "my_feature_columns = [\n",
    "    tf.contrib.layers.real_valued_column('SepalLength', dimension=1, dtype=tf.float32),\n",
    "    tf.contrib.layers.real_valued_column('SepalWidth', dimension=1, dtype=tf.float32),\n",
    "    tf.contrib.layers.real_valued_column('PetalLength', dimension=1, dtype=tf.float32),\n",
    "    tf.contrib.layers.real_valued_column('PetalWidth', dimension=1, dtype=tf.float32)\n",
    "]\n",
    "\n",
    "tf.contrib.layers.real_valued_column\n",
    "\n",
    "# format data as required by the tensorflow framework\n",
    "x = {\n",
    "    'SepalLength': numpy.array(training_df['SepalLength']),\n",
    "    'SepalWidth': numpy.array(training_df['SepalWidth']),\n",
    "    'PetalLength': numpy.array(training_df['PetalLength']),\n",
    "    'PetalWidth': numpy.array(training_df['PetalWidth'])\n",
    "}\n",
    "\n",
    "#neural network\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "       feature_columns=my_feature_columns,\n",
    "       hidden_units=[10, 10],\n",
    "       n_classes=3)\n",
    "\n",
    "\n",
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=x,\n",
    "    y=numpy.array(training_df['label']).astype(int),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# Train model.\n",
    "classifier.train(input_fn=train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-04-17:11:52\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\_domine3\\AppData\\Local\\Temp\\tmp388xdcy3\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-04-17:11:53\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.93333334, average_loss = 0.21500692, global_step = 2000, loss = 6.4502077\n",
      "Test Accuracy:  0.93333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test accuracy of the model\n",
    "# format data as required by the tensorflow framework\n",
    "x = {\n",
    "    'SepalLength': numpy.array(test_df['SepalLength']),\n",
    "    'SepalWidth': numpy.array(test_df['SepalWidth']),\n",
    "    'PetalLength': numpy.array(test_df['PetalLength']),\n",
    "    'PetalWidth': numpy.array(test_df['PetalWidth'])\n",
    "}\n",
    "\n",
    "# Define the training inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=x,\n",
    "    y=numpy.array(test_df['label']).astype(int),\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "\n",
    "print(\"Test Accuracy: \", accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-714e3cbf8a63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# format data as required by the tensorflow framework\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m x = {\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;34m'SepalLength'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7.4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;34m'SepalWidth'\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;34m'PetalLength'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6.1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "# We do some more manual testing\n",
    "# format data as required by the tensorflow framework\n",
    "x = {\n",
    "    'SepalLength': numpy.array([5.0, 6.7, 7.4]),\n",
    "    'SepalWidth':  numpy.array([3.5, 3.1, 2.8]),\n",
    "    'PetalLength': numpy.array([1.3, 4.4, 6.1]),\n",
    "    'PetalWidth':  numpy.array([0.3, 1.4, 1.9])\n",
    "}\n",
    "\n",
    "expected = numpy.array([0, 1, 2])\n",
    "\n",
    "# Define the training inputs\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=x,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "predictions = classifier.predict(input_fn=predict_input_fn)\n",
    "\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(class_id, 100 * probability, expec))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\_domine3\\AppData\\Local\\Temp\\tmp388xdcy3\\model.ckpt-2000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"stored_model\\\\temp-b'1528132320'\\\\saved_model.pbtxt\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'stored_model\\\\1528132320'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfrecord_serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(tf.contrib.layers.create_feature_spec_for_parsing(my_feature_columns))  \n",
    "\n",
    "def serving_input_receiver_fn():\n",
    "    serialized_tf_example = tf.placeholder(dtype=tf.string, shape=[None], name='input_tensors')\n",
    "    receiver_tensors      = {\"predictor_inputs\": serialized_tf_example}\n",
    "    feature_spec          = {'SepalLength': tf.FixedLenFeature([25],tf.float32),\n",
    "                            'SepalWidth': tf.FixedLenFeature([25],tf.float32),\n",
    "                            'PetalLength': tf.FixedLenFeature([25],tf.float32),\n",
    "                            'PetalWidth': tf.FixedLenFeature([25],tf.float32)}\n",
    "    features              = tf.parse_example(serialized_tf_example, feature_spec)\n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n",
    "\n",
    "\n",
    "classifier.export_savedmodel(export_dir_base=\"stored_model\", serving_input_receiver_fn  = serving_input_receiver_fn,as_text=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
